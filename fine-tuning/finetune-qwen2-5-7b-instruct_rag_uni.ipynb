{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:41:22.963725Z",
     "iopub.status.busy": "2025-03-23T16:41:22.963412Z",
     "iopub.status.idle": "2025-03-23T16:41:52.092292Z",
     "shell.execute_reply": "2025-03-23T16:41:52.091194Z",
     "shell.execute_reply.started": "2025-03-23T16:41:22.963698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dataset evaluate transformers[sentencepiece]\n",
    "!pip install transformers trl==0.8.3 peft bitsandbytes\n",
    "!pip install loguru rouge_score bert_score\n",
    "!pip install --upgrade nltk\n",
    "!pip install fire wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:41:52.093893Z",
     "iopub.status.busy": "2025-03-23T16:41:52.093534Z",
     "iopub.status.idle": "2025-03-23T16:42:16.078403Z",
     "shell.execute_reply": "2025-03-23T16:42:16.077471Z",
     "shell.execute_reply.started": "2025-03-23T16:41:52.093847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from huggingface_hub import login\n",
    "import os, torch, wandb, fire, evaluate\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, logging, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model, AutoPeftModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:42:16.080196Z",
     "iopub.status.busy": "2025-03-23T16:42:16.079591Z",
     "iopub.status.idle": "2025-03-23T16:42:20.908447Z",
     "shell.execute_reply": "2025-03-23T16:42:20.907863Z",
     "shell.execute_reply.started": "2025-03-23T16:42:16.080172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds1 = load_dataset(\"sailor2/Vietnamese_RAG\", \"BKAI_RAG\", split=\"train[:1141]\")\n",
    "\n",
    "ds2 = load_dataset(\"sailor2/Vietnamese_RAG\", \"LegalRAG\", split=\"train[:3176]\")\n",
    "\n",
    "ds3 = load_dataset(\"sailor2/Vietnamese_RAG\", \"expert\", split=\"train[:1772]\")\n",
    "\n",
    "ds4 = load_dataset(\"luzox/UTEHY_QA\", split=\"train+test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T16:41:12.770146Z",
     "iopub.status.idle": "2025-03-23T16:41:12.770368Z",
     "shell.execute_reply": "2025-03-23T16:41:12.770276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds1 = ds1.train_test_split(test_size=0.04)\n",
    "ds2 = ds2.train_test_split(test_size=0.03)\n",
    "ds3 = ds3.train_test_split(test_size=0.03)\n",
    "ds4 = ds4.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-23T16:41:12.771102Z",
     "iopub.status.idle": "2025-03-23T16:41:12.771475Z",
     "shell.execute_reply": "2025-03-23T16:41:12.771320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(ds1)\n",
    "print(ds2)\n",
    "print(ds3)\n",
    "print(ds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:41:52.390044Z",
     "iopub.status.busy": "2025-03-23T15:41:52.389739Z",
     "iopub.status.idle": "2025-03-23T15:41:52.398004Z",
     "shell.execute_reply": "2025-03-23T15:41:52.397085Z",
     "shell.execute_reply.started": "2025-03-23T15:41:52.390023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(ds1[\"train\"].features)\n",
    "print('--'*50)\n",
    "print(ds2[\"train\"].features)\n",
    "print('--'*50)\n",
    "print(ds3[\"train\"].features)\n",
    "print('--'*50)\n",
    "print(ds4[\"train\"].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:41:55.999765Z",
     "iopub.status.busy": "2025-03-23T15:41:55.999369Z",
     "iopub.status.idle": "2025-03-23T15:41:56.009296Z",
     "shell.execute_reply": "2025-03-23T15:41:56.008553Z",
     "shell.execute_reply.started": "2025-03-23T15:41:55.999731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds3 = ds3.remove_columns([\"system\", \"field\",\"spec_field\", \"question_type\",\"question_type_symbol\"])\n",
    "\n",
    "ds3 = ds3.rename_columns({\"revised_answer\": \"answer\", \"revised_claims\": \"context\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:41:56.439968Z",
     "iopub.status.busy": "2025-03-23T15:41:56.439654Z",
     "iopub.status.idle": "2025-03-23T15:41:56.447466Z",
     "shell.execute_reply": "2025-03-23T15:41:56.446803Z",
     "shell.execute_reply.started": "2025-03-23T15:41:56.439944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ds5 = ds5.remove_columns([\"groundedness_score\", \"groundedness_eval\",\"relevance_score\", \"standalone_score\",\"standalone_eval\", \"relevance_eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:41:56.985899Z",
     "iopub.status.busy": "2025-03-23T15:41:56.985591Z",
     "iopub.status.idle": "2025-03-23T15:41:56.993240Z",
     "shell.execute_reply": "2025-03-23T15:41:56.992570Z",
     "shell.execute_reply.started": "2025-03-23T15:41:56.985877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ds6 = ds6.remove_columns([\"groundedness_score\", \"groundedness_eval\",\"relevance_score\", \"standalone_score\",\"standalone_eval\", \"relevance_eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:41:58.586692Z",
     "iopub.status.busy": "2025-03-23T15:41:58.586356Z",
     "iopub.status.idle": "2025-03-23T15:42:00.664536Z",
     "shell.execute_reply": "2025-03-23T15:42:00.663913Z",
     "shell.execute_reply.started": "2025-03-23T15:41:58.586665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "from datasets.features import Sequence as DatasetsSequence\n",
    "\n",
    "def standardize_dataset(dataset_dict):\n",
    "    # Handle DatasetDict (with train/test/validation splits)\n",
    "    if hasattr(dataset_dict, 'keys') and isinstance(dataset_dict, dict):\n",
    "        standardized_dict = {}\n",
    "        \n",
    "        for split_name, ds in dataset_dict.items():\n",
    "            def transform_example(example):\n",
    "                standardized = {\n",
    "                    'question': example['question'],\n",
    "                    'answer': example['answer']\n",
    "                }\n",
    "                \n",
    "                # Check the actual data type of the context\n",
    "                if isinstance(example['context'], list):\n",
    "                    standardized['context'] = ' '.join([str(item) for item in example['context']])\n",
    "                else:\n",
    "                    standardized['context'] = example['context']\n",
    "                    \n",
    "                return standardized\n",
    "            \n",
    "            standardized_dict[split_name] = ds.map(transform_example)\n",
    "        \n",
    "        return standardized_dict\n",
    "    else:\n",
    "        # Handle a single Dataset object\n",
    "        def transform_example(example):\n",
    "            standardized = {\n",
    "                'question': example['question'],\n",
    "                'answer': example['answer']\n",
    "            }\n",
    "            \n",
    "            # Check the actual data type of the context\n",
    "            if isinstance(example['context'], list):\n",
    "                standardized['context'] = ' '.join([str(item) for item in example['context']])\n",
    "            else:\n",
    "                standardized['context'] = example['context']\n",
    "                \n",
    "            return standardized\n",
    "        \n",
    "        return dataset_dict.map(transform_example)\n",
    "\n",
    "# Apply the standardization to all datasets\n",
    "standardized_ds1 = standardize_dataset(ds1)\n",
    "standardized_ds2 = standardize_dataset(ds2)\n",
    "standardized_ds3 = standardize_dataset(ds3)\n",
    "standardized_ds4 = standardize_dataset(ds4)\n",
    "# standardized_ds6 = standardize_dataset(ds6)\n",
    "\n",
    "# Now you can concatenate them - assuming they all have the same splits\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# If they have train/test/validation splits\n",
    "result = {}\n",
    "for split in standardized_ds1.keys():\n",
    "    datasets_to_concat = [\n",
    "        standardized_ds1[split], \n",
    "        standardized_ds2[split], \n",
    "        standardized_ds3[split], \n",
    "        standardized_ds4[split], \n",
    "        # standardized_ds6[split]\n",
    "    ]\n",
    "    result[split] = concatenate_datasets(datasets_to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:42:02.016081Z",
     "iopub.status.busy": "2025-03-23T15:42:02.015769Z",
     "iopub.status.idle": "2025-03-23T15:42:02.020835Z",
     "shell.execute_reply": "2025-03-23T15:42:02.020107Z",
     "shell.execute_reply.started": "2025-03-23T15:42:02.016057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:42:02.799130Z",
     "iopub.status.busy": "2025-03-23T15:42:02.798817Z",
     "iopub.status.idle": "2025-03-23T15:42:03.260836Z",
     "shell.execute_reply": "2025-03-23T15:42:03.260104Z",
     "shell.execute_reply.started": "2025-03-23T15:42:02.799102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = result['train'].to_pandas()\n",
    "df_test = result['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-23T16:15:49.530317Z",
     "iopub.status.busy": "2025-03-23T16:15:49.530012Z",
     "iopub.status.idle": "2025-03-23T16:15:49.542975Z",
     "shell.execute_reply": "2025-03-23T16:15:49.542013Z",
     "shell.execute_reply.started": "2025-03-23T16:15:49.530294Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:15:21.516822Z",
     "iopub.status.busy": "2025-03-23T16:15:21.516464Z",
     "iopub.status.idle": "2025-03-23T16:15:35.264303Z",
     "shell.execute_reply": "2025-03-23T16:15:35.263686Z",
     "shell.execute_reply.started": "2025-03-23T16:15:21.516792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.login(key='')\n",
    "run = wandb.init(\n",
    "    project='Instruction fine-tune Qwen2.5-7B A100-80GB-ex',\n",
    "    job_type='training',\n",
    "    name='v2',\n",
    "    anonymous='allow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:19:28.188410Z",
     "iopub.status.busy": "2025-03-23T16:19:28.188061Z",
     "iopub.status.idle": "2025-03-23T16:19:28.373334Z",
     "shell.execute_reply": "2025-03-23T16:19:28.372683Z",
     "shell.execute_reply.started": "2025-03-23T16:19:28.188381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_instruction_prompt(sample):\n",
    "    context = sample['context']\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    instruction_prompt = f\"<|im_start|>system\\nBạn là chuyên gia tư vấn, trả lời các câu hỏi bằng tiếng Việt.<|im_end|>\\n<|im_start|>user\\nDựa vào nội dung văn bản sau:\\n{context}\\nBạn hãy đưa ra câu trả lời cho câu hỏi:\\n{question}<|im_end|>\\n<|im_start|>assistant\\n{answer}<|im_end|>\"\n",
    "    return instruction_prompt\n",
    "\n",
    "df_train['instruction'] = df_train.apply(process_instruction_prompt, axis=1)\n",
    "df_test['instruction'] = df_test.apply(process_instruction_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-23T16:19:58.303936Z",
     "iopub.status.busy": "2025-03-23T16:19:58.303610Z",
     "iopub.status.idle": "2025-03-23T16:19:58.310671Z",
     "shell.execute_reply": "2025-03-23T16:19:58.309656Z",
     "shell.execute_reply.started": "2025-03-23T16:19:58.303906Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df_train['instruction'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:21:25.751421Z",
     "iopub.status.busy": "2025-03-23T16:21:25.751024Z",
     "iopub.status.idle": "2025-03-23T16:21:25.763955Z",
     "shell.execute_reply": "2025-03-23T16:21:25.762896Z",
     "shell.execute_reply.started": "2025-03-23T16:21:25.751373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "number_of_val_samples = 500\n",
    "\n",
    "df_val = df_train.sample(n=number_of_val_samples, random_state=42)\n",
    "df_train.drop(index=df_val.index, inplace=True)\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:21:44.504897Z",
     "iopub.status.busy": "2025-03-23T16:21:44.504520Z",
     "iopub.status.idle": "2025-03-23T16:21:46.745971Z",
     "shell.execute_reply": "2025-03-23T16:21:46.745322Z",
     "shell.execute_reply.started": "2025-03-23T16:21:44.504869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_pandas(df_train, preserve_index = False)\n",
    "dataset_val = Dataset.from_pandas(df_val, preserve_index = False)\n",
    "dataset_test = Dataset.from_pandas(df_test, preserve_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:23:11.651513Z",
     "iopub.status.busy": "2025-03-23T16:23:11.651152Z",
     "iopub.status.idle": "2025-03-23T16:23:11.655848Z",
     "shell.execute_reply": "2025-03-23T16:23:11.655088Z",
     "shell.execute_reply.started": "2025-03-23T16:23:11.651460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = 'Qwen/Qwen2.5-7B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd projects/Tunning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:23:28.714731Z",
     "iopub.status.busy": "2025-03-23T16:23:28.714353Z",
     "iopub.status.idle": "2025-03-23T16:23:28.719147Z",
     "shell.execute_reply": "2025-03-23T16:23:28.718277Z",
     "shell.execute_reply.started": "2025-03-23T16:23:28.714701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch = 2\n",
    "learning_rate = 2e-4\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T16:24:09.714881Z",
     "iopub.status.busy": "2025-03-23T16:24:09.714558Z",
     "iopub.status.idle": "2025-03-23T16:28:21.755657Z",
     "shell.execute_reply": "2025-03-23T16:28:21.754893Z",
     "shell.execute_reply.started": "2025-03-23T16:24:09.714858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "device_map = {\"\": current_device}\n",
    "print(f\"Loading model onto device: {current_device}\")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(r=16,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.05,\n",
    "                        bias='none',\n",
    "                        task_type=\"CAUSAL_LM\",\n",
    "                        target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj'])\n",
    "\n",
    "\n",
    "model = get_peft_model(model, peft_config=peft_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./Qwen2.5-7B/checkpoint_16bit',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim='adamw_torch',\n",
    "    num_train_epochs=epoch,\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=10,\n",
    "    warmup_steps=10,\n",
    "    learning_rate=learning_rate,\n",
    "    bf16=True,                 \n",
    "    group_by_length=True,\n",
    "    report_to='wandb'\n",
    ")\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    args=training_args,\n",
    "    dataset_text_field='instruction'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-23T16:33:49.052Z",
     "iopub.execute_input": "2025-03-23T16:28:46.864565Z",
     "iopub.status.busy": "2025-03-23T16:28:46.864228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"./Qwen2.5-7B/model\"\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
